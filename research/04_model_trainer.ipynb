{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\PracticeProjects\\\\NLP_Insurance_intent_Detection\\\\nlp_intent'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path : Path\n",
    "    model_ckpt : Path\n",
    "    num_train_epochs : int\n",
    "    learning_rate : float\n",
    "    per_device_train_batch_size : int\n",
    "    per_device_eval_batch_size : int\n",
    "    weight_decay : float\n",
    "    evaluation_strategy : str\n",
    "    disable_tqdm : bool\n",
    "    logging_steps : int\n",
    "    log_level : str      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Manager\n",
    "\n",
    "from intent.constants import *\n",
    "from intent.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        #print(CONFIG_FILE_PATH)\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath) \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "        create_directories([config.root_dir])\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_ckpt = config.model_ckpt,\n",
    "            num_train_epochs =  params.num_train_epochs,\n",
    "            learning_rate = params.learning_rate,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = params.per_device_eval_batch_size,\n",
    "            weight_decay = params.weight_decay,\n",
    "            logging_steps = params.logging_steps,\n",
    "            evaluation_strategy = params.evaluation_strategy,\n",
    "            disable_tqdm = params.disable_tqdm,\n",
    "            log_level = params.log_level,\n",
    "        )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\Anaconda3\\envs\\nlp_intent_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-17 02:22:27,898: INFO: config: PyTorch version 2.3.0+cu118 available.]\n"
     ]
    }
   ],
   "source": [
    "# Component\n",
    "\n",
    "import os\n",
    "from intent.logging import logger\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config:ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def compute_metrics(self, pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        f1 = f1_score(labels, preds, average= \"weighted\")\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\"f1\" : f1, \"accuracy\" : acc}\n",
    "    \n",
    "    def train(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        num_labels = 77\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(self.config.model_ckpt, num_labels = num_labels).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        train_dataset_encoded = load_from_disk(os.path.join(self.config.data_path, \"train_dataset_encoded\"))\n",
    "        test_dataset_encoded = load_from_disk(os.path.join(self.config.data_path, \"test_dataset_encoded\"))\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = os.path.join(self.config.root_dir, \"training_output_directory\"),\n",
    "            num_train_epochs = self.config.num_train_epochs,\n",
    "            per_device_train_batch_size = self.config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = self.config.per_device_eval_batch_size,\n",
    "            weight_decay = self.config.weight_decay,\n",
    "            logging_steps = self.config.logging_steps,\n",
    "            evaluation_strategy = self.config.evaluation_strategy,\n",
    "            disable_tqdm = self.config.disable_tqdm,\n",
    "            log_level = self.config.log_level,\n",
    "            learning_rate = self.config.learning_rate,\n",
    "           \n",
    "        )\n",
    "        trainer = Trainer(model = model,\n",
    "                          args = training_args,\n",
    "                          compute_metrics = self.compute_metrics,\n",
    "                          train_dataset = train_dataset_encoded,\n",
    "                          eval_dataset = test_dataset_encoded,\n",
    "                          tokenizer = tokenizer\n",
    "                          )\n",
    "        \n",
    "        trainer.train()\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir, f\"{self.config.model_ckpt}-finetuned-banking77\"))\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir, \"tokenizer-finetuned-banking77\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-17 02:22:28,171: INFO: common: YAML file: D:\\PracticeProjects\\NLP_Insurance_intent_Detection\\nlp_intent\\config\\config.yaml loaded successfully]\n",
      "[2024-05-17 02:22:28,174: INFO: common: YAML file: D:\\PracticeProjects\\NLP_Insurance_intent_Detection\\nlp_intent\\params.yaml loaded successfully]\n",
      "[2024-05-17 02:22:28,175: INFO: common: created directory at: artifacts]\n",
      "[2024-05-17 02:22:28,177: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\Anaconda3\\envs\\nlp_intent_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                  \n",
      " 10%|█         | 157/1570 [01:22<09:31,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8220016956329346, 'eval_f1': 0.634310484760339, 'eval_accuracy': 0.6711038961038961, 'eval_runtime': 6.2266, 'eval_samples_per_second': 494.649, 'eval_steps_per_second': 7.869, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 200/1570 [01:44<11:28,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8009, 'grad_norm': 3.7668073177337646, 'learning_rate': 4.3630573248407646e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 314/1570 [02:46<08:24,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6709254384040833, 'eval_f1': 0.8711004050789583, 'eval_accuracy': 0.8756493506493507, 'eval_runtime': 6.1663, 'eval_samples_per_second': 499.486, 'eval_steps_per_second': 7.946, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 400/1570 [03:28<09:27,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7552, 'grad_norm': 2.9027862548828125, 'learning_rate': 3.7261146496815283e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 30%|███       | 471/1570 [04:08<07:16,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4090560972690582, 'eval_f1': 0.9038822562912687, 'eval_accuracy': 0.9042207792207793, 'eval_runtime': 6.0649, 'eval_samples_per_second': 507.841, 'eval_steps_per_second': 8.079, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 600/1570 [05:13<07:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2874, 'grad_norm': 1.9692418575286865, 'learning_rate': 3.089171974522293e-05, 'epoch': 3.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 628/1570 [05:32<06:14,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31654125452041626, 'eval_f1': 0.9239628964995817, 'eval_accuracy': 0.9237012987012987, 'eval_runtime': 6.2165, 'eval_samples_per_second': 495.454, 'eval_steps_per_second': 7.882, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|█████     | 785/1570 [06:55<05:11,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2913801372051239, 'eval_f1': 0.9246583629222934, 'eval_accuracy': 0.9243506493506494, 'eval_runtime': 6.15, 'eval_samples_per_second': 500.812, 'eval_steps_per_second': 7.967, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 800/1570 [07:02<06:21,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1426, 'grad_norm': 1.7864775657653809, 'learning_rate': 2.4522292993630575e-05, 'epoch': 5.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 60%|██████    | 942/1570 [08:17<04:07,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2921842634677887, 'eval_f1': 0.9273920366763152, 'eval_accuracy': 0.9272727272727272, 'eval_runtime': 6.0926, 'eval_samples_per_second': 505.531, 'eval_steps_per_second': 8.043, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1000/1570 [08:45<04:36,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0708, 'grad_norm': 0.5651630759239197, 'learning_rate': 1.8152866242038215e-05, 'epoch': 6.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|███████   | 1099/1570 [09:41<03:12,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2949126660823822, 'eval_f1': 0.9250382408439562, 'eval_accuracy': 0.925, 'eval_runtime': 6.1598, 'eval_samples_per_second': 500.013, 'eval_steps_per_second': 7.955, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1200/1570 [10:30<03:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0397, 'grad_norm': 1.0202494859695435, 'learning_rate': 1.178343949044586e-05, 'epoch': 7.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 1256/1570 [11:04<02:05,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29074394702911377, 'eval_f1': 0.9257397260129638, 'eval_accuracy': 0.9256493506493506, 'eval_runtime': 6.3112, 'eval_samples_per_second': 488.019, 'eval_steps_per_second': 7.764, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1400/1570 [12:15<01:25,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0252, 'grad_norm': 0.37820175290107727, 'learning_rate': 5.414012738853504e-06, 'epoch': 8.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|█████████ | 1413/1570 [12:28<01:03,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29550763964653015, 'eval_f1': 0.9292959135889873, 'eval_accuracy': 0.9292207792207792, 'eval_runtime': 6.323, 'eval_samples_per_second': 487.114, 'eval_steps_per_second': 7.75, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1570/1570 [13:52<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.293503999710083, 'eval_f1': 0.9295879631152127, 'eval_accuracy': 0.9295454545454546, 'eval_runtime': 6.1165, 'eval_samples_per_second': 503.559, 'eval_steps_per_second': 8.011, 'epoch': 10.0}\n",
      "{'train_runtime': 832.4287, 'train_samples_per_second': 120.166, 'train_steps_per_second': 1.886, 'train_loss': 0.5270263790324995, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Pipeline component\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config = model_trainer_config) \n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_intent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
